---
author: Naseem Dillman-Hasso
categories:
- Open Science
- Open Scholarship
- Measurement
date: "2021-12-24"
draft: false
excerpt: Improving the quality of scientific research and measurement is necessary for the future of scholarship.
featured: true
layout: single-sidebar
links:
- icon: door-open
  icon_pack: fas
  name: COS
  url: https://www.cos.io/
- icon: newspaper
  icon_pack: far
  name: False-Positive Article
  url: https://doi.org/10.1177/0956797611417632
- icon: newspaper
  icon_pack: far
  name: Measurement Article
  url: https://doi.org/10.1177/2515245920952393
subtitle: ""
tags:
- hugo-site
title: Open Science
---
Open science and scholarship is the way forward in research disciplines. It's obvious that there is a major problem in the ways we conduct, evaluate, and disseminate research. Studies aren't replicating, both in [psychology](https://www.science.org/doi/10.1126/science.aac4716) and [other fields](https://www.nature.com/news/1-500-scientists-lift-the-lid-on-reproducibility-1.19970). There is a whole host of potential explanations for this: our publishing systems, incentive structures, accidental misuse of statistical tools, and of course, malicious misrepresentation of data. But that doesn't mean that there aren't solutions out there, but they may be difficult to implement, and implementation can have unintended consequences for early career researchers or individuals who aren't at wealthy and powerful institutions.

I support implementation of a few easy solutions that everyone can implement:
- *Pre-registration* of eligible studies. While exploratory research is incredibly valuable, it's incredibly important to justify decisions before they're made, in order to avoid p-hacking or HARK-ing.
- [*The 21-word solution.*](http://dx.doi.org/10.2139/ssrn.2160588) This simple sentence, added to the methods sections of emperical research, reads: "We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study."
- *Preprints.* Posting versions of articles before they are peer reviewed on public repositories such as [PsyArXiv](https://psyarxiv.com/) increases transparency, visibility, and creates a time-stamped credited version of when a research project was conducted.
- *Sharing of data, code, and materials.* Along with preprints, sharing data and code (of course, when applicable) makes it easier for individuals to replicate studies, check the quality of code, and conduct meta-analytic studies.

